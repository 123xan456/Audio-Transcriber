{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "### Diarization\n",
    "https://colab.research.google.com/drive/1X5XTiob6irFq8NJM831S0ADwz5_wIS-r#scrollTo=M_i_C1dVFp0J\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the required modules and setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import wget\n",
    "import re\n",
    "from pathlib import Path\n",
    "from torch import hub\n",
    "\n",
    "device = 'cuda'\n",
    "CACHE_DIRECTORY = Path(os.getcwd())/'.cache'\n",
    "# hub.set_dir(str(CACHE_DIRECTORY))\n",
    "os.environ['TRANSFORMERS_CACHE'] = str(CACHE_DIRECTORY)\n",
    "os.environ['NEMO_CACHE_DIR'] = str(CACHE_DIRECTORY)\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import whisperx\n",
    "\n",
    "from Configs import RESOURCES\n",
    "from TranscriptionUtils import Transcriber\n",
    "from SummarizationUtils import SummaryUtils\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I can create an end point for you that at the end of the day, just before the person come in, you just update it. For that person to become that signatory. Because this was already proposed by Choraya the last time to be able to update the signatory. This is not a problem. So meaning if that's the case, during the very first time that we call you to create the agreement that time, we only pass you the borrower. Correct. Then after once we know who is who already, then we pass you another secretary. Because what happen is when I talk to the secure PDF, I do not certify, once I certify that part, I do not flatten the debt field. The rest all I flatten, but only the one I don't flatten is those signing fields for the lawyer. That's the only one we are going to do. So that means the hashing that we have at that time will not be the same. So once the lawyer come in and put in the details, I think that hashing will change again. That will affect your partner. I think the hashing throughout the entire, like last time you mentioned, I think still can be the same. whereby because when we fill in the signatory that time right, it is not being captured yet. So the form field that what we have given will not change. Correct. Not only the sanitary feel, but the name of the company. The cash will be one of the value, or probably IC, or probably some other company name. That part only will change. Yes, correct. Definitely the borrower will sign before the borrower sign, right? Ah, no. No, the borrower will sign first. The borrower will sign first. Then it will be the last person to sign. Then the cash value is before the cash value we get from this system. The hash value that is there by the time I send to him, when I create the document the first time. When I create the document the first time. The document without any signature. Without any signature. No, it will be after I add in all of the name, the address, everything without the signature. So it will be the hash before you certify it. Okay, it will be the hash before I certify, correct? But by that time, when you first pass to me, Clement's signature will already be signed? No, not yet. It will be the last signature to be signed. Oh, Clement will be the last one? So I think part of the signatory will be blank? Signatory is blank. Oh, okay. When you certify all the terms of the agreement. Okay, then? Okay lah. That means that when I create the document the first time, and I go to you, flatten all of, put in all of those things, except I don't flatten the signatory part, that is fine. Then I hash that document, and copy it already, because that hash is what I mean to pass to them. Okay lah. No, that hash should be something you generate, is that not? You generate that, you return that hash to him. I return the content I didn't put. You don't hash it, let him sign and hash it and return you the signature as hash. Because otherwise I'm scared your algorithm is different. Oh, so you are the hashing now? You take the CID. Okay, right. Or the CID will become the hash lah? Can also lah? The CID will crack down the fork. So I will give you the CID to be embedded into the document and that CID is actually treated as the hash. No, you give him the hash, don't give him the CID. I don't want CIDF, just give me the hash. I will pass it to him, the CID. Hash, hash, hash. I will give you the hash of that. To me, to us, it's a CID. Okay, fine. Okay, so I think that's true. So nothing changed in my card? Nothing, nothing changed in your card. So when the doc finishes the discussion. So with this arrangement, that should be greatly help on the application side. So we will go on to this understanding. So then the next item would be, because I think it would be easier for lawyer to use digital signature. That's why we suggest to use digital signature for the lawyer. Because normally lawyer should be working on the desktop. So if you want them to use this signature from the mobile, I worry that it will be quite complicated for them also. So since digital signature, we can just like our site, a bit balanced digital signature, it just stops at space-in only. So that's why we... They have to be given beforehand, no? before hand, no? Ah, yep. in general.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleAudio = RESOURCES/\"audio\"/\"audio.wav\"\n",
    "sampleAudioPath = str(RESOURCES/\"audio\"/\"audio.wav\")\n",
    "\n",
    "transcriber = Transcriber()\n",
    "resultInitial = transcriber.transcribe(sampleAudioPath)\n",
    "\n",
    "resultInitial[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultInitial[\"language\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment using whisperX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'WAV2VEC2_ASR_LARGE_LV60K_960H'\n",
    "alignmentModel, metadata = whisperx.load_align_model(language_code=resultInitial[\"language\"], device=device, model_name=modelName)\n",
    "resultAligned = whisperx.align(resultInitial[\"segments\"], alignmentModel, metadata, sampleAudioPath, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing words <> timestamps mapping in a file.\n",
    "with open(str(CACHE_DIRECTORY/'word_ts.text'), 'w+') as f:\n",
    "    for line in resultAligned['word_segments']:\n",
    "        line_temp = line.copy()\n",
    "        # WhisperX don't put a space after word but just to make sure.\n",
    "        line_temp['text'] = line_temp['text'].strip()\n",
    "        f.write(f'{json.dumps(line_temp)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarize_manifest = {\n",
    "    'audio_filepath': sampleAudioPath,\n",
    "    'offset': 0,\n",
    "    'duration':  None,\n",
    "    'label': \"infer\",\n",
    "    'text': \"-\",\n",
    "    'num_speakers': None,\n",
    "    'rttm_filepath': str(CACHE_DIRECTORY/\"diarized.rttm\"),\n",
    "    'uniq_id': \"\"\n",
    "}\n",
    "\n",
    "with open(CACHE_DIRECTORY/\"manifest.json\", 'w') as f:\n",
    "    f.write(json.dumps(diarize_manifest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = str(CACHE_DIRECTORY/'diar_infer_meeting.yaml')\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_meeting.yaml\"\n",
    "    MODEL_CONFIG = wget.download(config_url, str(CACHE_DIRECTORY))\n",
    "\n",
    "config = OmegaConf.load(MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_workers = 1\n",
    "config.batch_size = 32\n",
    "\n",
    "config.diarizer.manifest_filepath = str(CACHE_DIRECTORY/\"manifest.json\")\n",
    "config.diarizer.out_dir = str(CACHE_DIRECTORY/\"diarized\")\n",
    "config.diarizer.speaker_embeddings.model_path = 'titanet_large'\n",
    "config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [1.5, 1.0, 0.5]\n",
    "config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [0.75, 0.5, 0.25]\n",
    "config.diarizer.speaker_embeddings.parameters.multiscale_weights = [0.33, 0.33, 0.33]\n",
    "config.diarizer.speaker_embeddings.parameters.save_embeddings = False\n",
    "\n",
    "config.diarizer.ignore_overlap = False\n",
    "config.diarizer.oracle_vad = False\n",
    "config.diarizer.collar = 0.25\n",
    "\n",
    "\n",
    "config.diarizer.vad.model_path = 'vad_multilingual_marblenet'\n",
    "config.diarizer.oracle_vad = False # ----> Not using oracle VAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models.msdd_models import ClusteringDiarizer\n",
    "\n",
    "model = ClusteringDiarizer(cfg=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.diarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_ts = []\n",
    "with open(str(CACHE_DIRECTORY/\"diarized\"/\"pred_rttms\"/(str(sampleAudio.stem) + \".rttm\")), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line_list = line.split(' ')\n",
    "        s = int(float(line_list[5]) * 1000)\n",
    "        e = s + int(float(line_list[8]) * 1000)\n",
    "        speaker_ts.append([s, e, int(line_list[11].split('_')[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ts = []\n",
    "with open(CACHE_DIRECTORY/'word_ts.text', 'r+') as f:\n",
    "    for line in f:\n",
    "        line_temp = json.loads(line)\n",
    "        word_ts.append(line_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_ts_anchor(s, e, option=\"start\"):\n",
    "    if option == \"end\":\n",
    "        return e\n",
    "    elif option == \"mid\":\n",
    "        return (s + e) / 2\n",
    "    return s\n",
    "\n",
    "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
    "    s, e, sp = spk_ts[0]\n",
    "    wrd_pos, turn_idx = 0, 0\n",
    "    wrd_spk_mapping = []\n",
    "    for wrd_dict in wrd_ts:\n",
    "        ws, we, wrd = (\n",
    "            int(wrd_dict[\"start\"] * 1000),\n",
    "            int(wrd_dict[\"end\"] * 1000),\n",
    "            wrd_dict[\"text\"],\n",
    "        )\n",
    "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
    "        while wrd_pos > float(e) and (turn_idx != len(spk_ts) - 1):\n",
    "            turn_idx += 1\n",
    "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
    "            s, e, sp = spk_ts[turn_idx]\n",
    "        result = {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
    "        wrd_spk_mapping.append(result)\n",
    "    return wrd_spk_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsm = get_words_speaker_mapping(word_ts, speaker_ts, 'start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_ending_punctuations = '.?!'\n",
    "\n",
    "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
    "  is_word_sentence_end = lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "  left_idx = word_idx\n",
    "  while (left_idx > 0 and word_idx - left_idx < max_words and\n",
    "          speaker_list[left_idx - 1] == speaker_list[left_idx] and\n",
    "          not is_word_sentence_end(left_idx - 1)):\n",
    "      left_idx -= 1\n",
    "      \n",
    "  return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
    "\n",
    "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
    "  is_word_sentence_end = lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "  right_idx = word_idx\n",
    "  while (right_idx < len(word_list) and right_idx - word_idx < max_words and\n",
    "          not is_word_sentence_end(right_idx)):\n",
    "      right_idx += 1\n",
    "      \n",
    "  return right_idx if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx) else -1\n",
    "\n",
    "def get_realigned_ws_mapping_with_punctuation(word_speaker_mapping, max_words_in_sentence = 50):\n",
    "  is_word_sentence_end = lambda x: x >= 0 and word_speaker_mapping[x]['word'][-1] in sentence_ending_punctuations\n",
    "  wsp_len = len(word_speaker_mapping)\n",
    "  \n",
    "  words_list, speaker_list = [], []\n",
    "  for k, line_dict in enumerate(word_speaker_mapping):\n",
    "      word, speaker = line_dict['word'], line_dict['speaker']\n",
    "      words_list.append(word)\n",
    "      speaker_list.append(speaker)\n",
    "\n",
    "  k = 0\n",
    "  while k < len(word_speaker_mapping):\n",
    "      line_dict = word_speaker_mapping[k]\n",
    "      if k < wsp_len - 1 and speaker_list[k] != speaker_list[k + 1] and not is_word_sentence_end(k):\n",
    "          left_idx = get_first_word_idx_of_sentence(k, words_list, speaker_list, max_words_in_sentence)\n",
    "          right_idx = get_last_word_idx_of_sentence(k, words_list, max_words_in_sentence - k + left_idx - 1) if left_idx > -1 else -1\n",
    "          if min(left_idx, right_idx) == -1:\n",
    "              k += 1\n",
    "              continue\n",
    "          \n",
    "          spk_labels = speaker_list[left_idx: right_idx + 1]\n",
    "          mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
    "          if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
    "              k += 1\n",
    "              continue\n",
    "          \n",
    "          speaker_list[left_idx: right_idx + 1] = [mod_speaker] * (right_idx - left_idx + 1)\n",
    "          k = right_idx\n",
    "      \n",
    "      k += 1\n",
    "  \n",
    "  k, realigned_list = 0, []\n",
    "  while k < len(word_speaker_mapping):\n",
    "      line_dict = word_speaker_mapping[k].copy()\n",
    "      line_dict['speaker'] = speaker_list[k]\n",
    "      realigned_list.append(line_dict)\n",
    "      k += 1\n",
    "      \n",
    "  \n",
    "  return realigned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
    "    s, e, spk = spk_ts[0]\n",
    "    prev_spk = spk\n",
    "\n",
    "    snts = []\n",
    "    snt = {'speaker': f'Speaker {spk}', 'start_time': s, 'end_time': e, 'text': ''}\n",
    "\n",
    "    for wrd_dict in word_speaker_mapping:\n",
    "        wrd, spk = wrd_dict['word'], wrd_dict['speaker']\n",
    "        s, e = wrd_dict['start_time'], wrd_dict['end_time']\n",
    "        if spk != prev_spk:\n",
    "            snts.append(snt)\n",
    "            snt = {'speaker': f'Speaker {spk}', 'start_time': s, 'end_time': e, 'text': ''}\n",
    "        else:\n",
    "            snt['end_time'] = e\n",
    "        snt['text'] += wrd + ' '\n",
    "        prev_spk = spk\n",
    "\n",
    "    snts.append(snt)\n",
    "    return snts\n",
    "\n",
    "def get_speaker_aware_transcript(sentences_speaker_mapping):\n",
    "  with open(CACHE_DIRECTORY/'diarization.txt', 'w') as f:\n",
    "    for sentence_dict in sentences_speaker_mapping:\n",
    "        sp = sentence_dict['speaker']\n",
    "        text = sentence_dict['text']\n",
    "        f.write(f'\\n\\n{sp}: {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
    "ssm = get_sentences_speaker_mapping(wsm, speaker_ts)\n",
    "get_speaker_aware_transcript(ssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarized = \"\"\n",
    "with open(CACHE_DIRECTORY/\"diarization.txt\", \"r\") as f:\n",
    "    diarized = f.read()\n",
    "    diarized = re.sub(\"\\n\", \"\", diarized).lower()\n",
    "diarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-01-13 17:43:00 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-01-13 17:43:00 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:00 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:01 nemo_logging:349] /opt/steven/Audio-Transcriber/venv/lib64/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2023-01-13 17:43:01 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:01 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:01 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:01 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-13 17:43:01 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01.103 --> 00:06.840]  I can create an end point for you that at the end of the day, just before the person come in, you just update it.\n",
      "[00:07.564 --> 00:09.919]  For that person to become that signatory.\n",
      "[00:10.161 --> 00:15.739]  Because this was already proposed by Choraya the last time to be able to update the signatory.\n",
      "[00:16.869 --> 00:17.556]  This is not a problem.\n",
      "[00:18.040 --> 00:26.419]  So meaning if that's the case, during the very first time that we call you to create the agreement that time, we only pass you the borrower.\n",
      "[00:27.102 --> 00:27.796]  Correct.\n",
      "[00:28.221 --> 00:32.274]  Then after once we know who is who already, then we pass you another secretary.\n",
      "[00:34.601 --> 00:46.817]  Because what happen is when I talk to the secure PDF, I do not certify, once I certify that part, I do not flatten the debt field.\n",
      "[00:49.301 --> 00:54.940]  The rest all I flatten, but only the one I don't flatten is those signing fields for the lawyer.\n",
      "[00:55.963 --> 01:00.960]  That's the only one we are going to do. So that means the hashing that we have at that time will not be the same.\n",
      "[01:01.924 --> 01:05.839]  So once the lawyer come in and put in the details, I think that hashing will change again.\n",
      "[01:06.061 --> 01:07.879]  That will affect your partner.\n",
      "[01:08.301 --> 01:17.940]  I think the hashing throughout the entire, like last time you mentioned, I think still can be the same.\n",
      "[01:18.882 --> 01:25.920]  whereby because when we fill in the signatory that time right, it is not being\n",
      "[01:26.321 --> 01:32.233]  captured yet. So the form field that what we have given will not change.\n",
      "[01:35.525 --> 01:35.858]  Correct.\n",
      "[01:35.980 --> 01:38.756]  Not only the sanitary feel, but the name of the company.\n",
      "[01:39.520 --> 01:45.179]  The cash will be one of the value, or probably IC, or probably some other company name.\n",
      "[01:45.784 --> 01:47.137]  That part only will change.\n",
      "[01:48.073 --> 01:48.400]  Yes, correct.\n",
      "[01:48.420 --> 01:51.179]  Definitely the borrower will sign before the borrower sign, right?\n",
      "[01:51.645 --> 01:52.298]  Ah, no.\n",
      "[01:52.683 --> 01:54.036]  No, the borrower will sign first.\n",
      "[01:54.584 --> 01:55.359]  The borrower will sign first.\n",
      "[01:55.501 --> 01:57.198]  Then it will be the last person to sign.\n",
      "[01:57.661 --> 02:02.300]  Then the cash value is before the cash value we get from this system.\n",
      "[02:02.420 --> 02:08.320]  The hash value that is there by the time I send to him, when I create the document the first time.\n",
      "[02:09.370 --> 02:10.360]  When I create the document the first time.\n",
      "[02:10.743 --> 02:12.057]  The document without any signature.\n",
      "[02:12.905 --> 02:14.299]  Without any signature.\n",
      "[02:14.601 --> 02:22.300]  No, it will be after I add in all of the name, the address, everything without the signature.\n",
      "[02:22.581 --> 02:26.360]  So it will be the hash before you certify it.\n",
      "[02:27.384 --> 02:30.938]  Okay, it will be the hash before I certify, correct?\n",
      "[02:31.460 --> 02:39.059]  But by that time, when you first pass to me, Clement's signature will already be signed?\n",
      "[02:39.420 --> 02:43.098]  No, not yet. It will be the last signature to be signed.\n",
      "[02:43.541 --> 02:45.097]  Oh, Clement will be the last one?\n",
      "[02:45.561 --> 02:48.656]  So I think part of the signatory will be blank?\n",
      "[02:49.645 --> 02:50.176]  Signatory is blank.\n",
      "[02:50.788 --> 02:51.278]  Oh, okay.\n",
      "[02:51.521 --> 02:54.299]  When you certify all the terms of the agreement.\n",
      "[02:54.925 --> 02:55.552]  Okay, then? Okay lah.\n",
      "[02:57.365 --> 03:00.199]  That means that when I create the document the first time,\n",
      "[03:00.501 --> 03:03.360]  and I go to you, flatten all of, put in all of those things,\n",
      "[03:03.521 --> 03:05.977]  except I don't flatten the signatory part, that is fine.\n",
      "[03:06.804 --> 03:08.117]  Then I hash that document,\n",
      "[03:08.702 --> 03:12.239]  and copy it already, because that hash is what I mean to pass to them.\n",
      "[03:12.706 --> 03:13.339]  Okay lah.\n",
      "[03:13.440 --> 03:16.179]  No, that hash should be something you generate,\n",
      "[03:16.561 --> 03:18.977]  is that not? You generate that, you return that hash to him.\n",
      "[03:20.867 --> 03:23.179]  I return the content I didn't put.\n",
      "[03:23.521 --> 03:26.998]  You don't hash it, let him sign and hash it and return you the signature as hash.\n",
      "[03:28.004 --> 03:30.158]  Because otherwise I'm scared your algorithm is different.\n",
      "[03:30.723 --> 03:31.875]  Oh, so you are the hashing now?\n",
      "[03:32.624 --> 03:33.359]  You take the CID.\n",
      "[03:33.522 --> 03:34.155]  Okay, right.\n",
      "[03:35.205 --> 03:36.655]  Or the CID will become the hash lah?\n",
      "[03:37.441 --> 03:38.196]  Can also lah?\n",
      "[03:38.461 --> 03:40.299]  The CID will crack down the fork.\n",
      "[03:40.601 --> 03:48.139]  So I will give you the CID to be embedded into the document and that CID is actually treated as the hash.\n",
      "[03:48.501 --> 03:50.339]  No, you give him the hash, don't give him the CID.\n",
      "[03:50.601 --> 03:54.199]  I don't want CIDF, just give me the hash.\n",
      "[03:54.521 --> 03:56.259]  I will pass it to him, the CID.\n",
      "[03:57.491 --> 03:58.279]  Hash, hash, hash.\n",
      "[03:58.501 --> 03:59.996]  I will give you the hash of that.\n",
      "[04:00.622 --> 04:02.218]  To me, to us, it's a CID.\n",
      "[04:02.824 --> 04:03.895]  Okay, fine.\n",
      "[04:04.963 --> 04:08.179]  Okay, so I think that's true.\n",
      "[04:08.501 --> 04:09.834]  So nothing changed in my card?\n",
      "[04:10.541 --> 04:12.319]  Nothing, nothing changed in your card.\n",
      "[04:12.521 --> 04:14.137]  So when the doc finishes the discussion.\n",
      "[04:15.223 --> 04:19.878]  So with this arrangement, that should be greatly help on the application side.\n",
      "[04:20.641 --> 04:24.818]  So we will go on to this understanding.\n",
      "[04:27.405 --> 04:33.300]  So then the next item would be, because I think it would be easier for lawyer to use digital signature.\n",
      "[04:33.541 --> 04:36.636]  That's why we suggest to use digital signature for the lawyer.\n",
      "[04:38.504 --> 04:42.179]  Because normally lawyer should be working on the desktop.\n",
      "[04:42.721 --> 04:51.059]  So if you want them to use this signature from the mobile, I worry that it will be quite complicated for them also.\n",
      "[04:51.721 --> 04:58.179]  So since digital signature, we can just like our site, a bit balanced digital signature, it just stops at space-in only.\n",
      "[04:58.706 --> 04:59.400]  So that's why we...\n",
      "[04:59.824 --> 05:01.299]  They have to be given beforehand, no?\n",
      "[05:01.563 --> 05:02.176]  before hand, no?\n",
      "[05:02.482 --> 05:03.138]  Ah, yep.\n",
      "[05:03.281 --> 05:03.504]  in general.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting manifest: 100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n",
      "vad: 100%|██████████| 7/7 [00:04<00:00,  1.62it/s]\n",
      "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "[1/3] extract embeddings: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]\n",
      "[2/3] extract embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
      "[3/3] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  4.59it/s]\n",
      "clustering: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from DiarizationUtils import Diarizer\n",
    "diarizer = Diarizer()\n",
    "diarized = diarizer.diarize(resultInitial, sampleAudioPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Speaker 0: i can create an end point for you that at the end of the day, just before the person come in, you just update it. for that person to become that signatory. because this was already proposed by choraya the last time to be able to update the signatory.  Speaker 1: this is not a problem. so meaning if that\\'s the case, during the very first time that we call you to create the agreement that time, we only pass you the borrower.  Speaker 0: correct.  Speaker 1: then after once we know who is who already, then we pass you another secretary.  Speaker 0: because what happen is when i talk to the secure pdf, i do not certify, once i certify that part, i do not flatten the debt field. the rest all i flatten, but only the one i don\\'t flatten is those signing fields for the lawyer.  Speaker 1: that\\'s the only one we are going to do. so that means the hashing that we have at that time will not be the same.  Speaker 0: so once the lawyer come in and put in the details, i think that hashing will change again.  Speaker 1: that will affect your partner. i think the hashing throughout the entire, like last time you mentioned, i think still can be the same. whereby because when we fill in the signatory that time right, it is not being captured yet. so the form field that what we have given will not change.  Speaker 0: correct.  Speaker 1: not only the sanitary feel, but the name of the company. the cash will be one of the value, or probably ic, or probably some other company name. that part only will change. yes, correct. definitely the borrower will sign before the borrower sign, right?  Speaker 0: ah, no. no, the borrower will sign first. the borrower will sign first. then it will be the last person to sign.  Speaker 1: then the cash value is before the cash value we get from this system. the hash value that is there by the time i send to him, when i create the document the first time.  Speaker 0: when i create the document the first time. the document without any signature. without any signature. no, it will be after i add in all of the name, the address, everything without the signature.  Speaker 1: so it will be the hash before you certify it.  Speaker 0: okay, it will be the hash before i certify, correct? but by that time, when you first pass to me, clement\\'s signature will already be signed?  Speaker 1: no, not yet. it will be the last signature to be signed. oh, clement will be the last one? so i think part of the signatory will be blank? signatory is blank. oh, okay. when you certify all the terms of the agreement.  Speaker 0: okay, then? okay lah. that means that when i create the document the first time, and i go to you, flatten all of, put in all of those things, except i don\\'t flatten the signatory part, that is fine.  Speaker 1: then i hash that document, and copy it already, because that hash is what i mean to pass to them. okay lah. no, that hash should be something you generate, is that not? you generate that, you return that hash to him.  Speaker 0: i return the content i didn\\'t put. you don\\'t hash it, let him sign and hash it and return you the signature as hash. because otherwise i\\'m scared your algorithm is different. oh, so you are the hashing now? you take the cid. okay, right. or the cid will become the hash lah? can also lah? the cid will crack down the fork. so i will give you the cid to be embedded into the document and that cid is actually treated as the hash.  Speaker 1: no, you give him the hash, don\\'t give him the cid.  Speaker 0: i don\\'t want cidf, just give me the hash. i will pass it to him, the cid. hash, hash, hash. i will give you the hash of that.  Speaker 1: to me, to us, it\\'s a cid. okay, fine. okay, so i think that\\'s true.  Speaker 0: so nothing changed in my card? nothing, nothing changed in your card. so when the doc finishes the discussion. so with this arrangement, that should be greatly help on the application side.  Speaker 1: so we will go on to this understanding. so then the next item would be, because i think it would be easier for lawyer to use digital signature. that\\'s why we suggest to use digital signature for the lawyer. because normally lawyer should be working on the desktop. so if you want them to use this signature from the mobile, i worry that it will be quite complicated for them also. so since digital signature, we can just like our site, a bit balanced digital signature, it just stops at space-in only. so that\\'s why we... they have to be given beforehand, no? before hand, no? ah, yep. in general.  \"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(diarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = SummaryUtils()\n",
    "summary = summarizer.summarize(diarized, maxLen=400, minLen=100, lengthPenalty=2.0, repetitionPenalty=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Speaker 0 and Speaker 1 discuss how to update the document before the person comes in to become a signatory. They agree that the hashing of the document will not change once the lawyer comes in and changes the details. The lawyer will use a digital signature on the document. Speaker 1 suggests to use a mobile app for the lawyer's signature, so they don't have to worry about it when the application is finished.   It was already proposed by choraya the last time, so nothing has changed.\\nbefore hand, no? ah, yep. in general. \"\n"
     ]
    }
   ],
   "source": [
    "print(repr(summary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Apr 11 2022, 06:30:15) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-10.0.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69596dc8392391b17b70d475f25ab62045fffb2c14301dd0c1afddfa9e87df53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
